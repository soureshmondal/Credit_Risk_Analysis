{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79ac1862"
   },
   "source": [
    "# **CREDIT RISK MODELING - BUSINESS UNDERSTANDING**\n",
    "\n",
    "**Problem:** Predict loan approval probability to minimize default risk\n",
    "\n",
    "**Success Metrics:** Precision, Recall, AUC-ROC, Business KPIs (approval rate, expected loss)\n",
    "\n",
    "**Target Variable:** Approved_Flag (P1=Low Risk, P2=Medium, P3=High, P4=Very High Risk)\n",
    "\n",
    "**Business Context:** Financial institution loan approval decision support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuJN9lvoZiBE"
   },
   "source": [
    "## ðŸ”Ž Data Inspection, Cleaning, and Merging Overview\n",
    "\n",
    "In this section, we prepare and validate the **Internal Bank Dataset**, **External CIBIL Dataset**, and the **Unseen Dataset** before merging them into a unified dataset for further modeling.  \n",
    "\n",
    "The workflow ensures **data quality, consistency, and integrity** by checking merge keys, duplicates, missing values, and overlaps across datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xqse_P5Mqqhk"
   },
   "source": [
    "# **Data Loading and Initial Inspection**\n",
    "This section loads the datasets and performs initial validation, including shape checks, duplicate identification, and sample data display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "GB5MsPcQktpu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cc0F9DfNZsGf"
   },
   "source": [
    "**Load Datasets**\n",
    "   - Load internal, external, and unseen CSV datasets into Pandas DataFrames.\n",
    "   - Purpose: bring raw data into the Colab environment for inspection and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "SR-rw8tPkN-p"
   },
   "outputs": [],
   "source": [
    "# upload datasets (csv files) into colab environment\n",
    "\n",
    "internal_df = pd.read_csv(\"../datasets/Internal_Bank_Dataset.csv\")\n",
    "external_df = pd.read_csv(\"../datasets/External_Cibil_Dataset.csv\")\n",
    "unseen_df = pd.read_csv(\"../datasets/Unseen_Dataset.csv\")\n",
    "\n",
    "# Dataset Link: https://www.kaggle.com/code/saurabhbadole/predictive-credit-risk-modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "v6dDoM05YfeY",
    "outputId": "f4218b65-d815-4b76-8775-915bf89374f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Convert Excel files to CSV while preserving all data\\ndef excel_to_csv_safe(excel_filename, csv_filename):\\n    \"\"\"\\n    Convert Excel to CSV without losing data\\n    \"\"\"\\n    # Read Excel with all data preserved\\n    df = pd.read_excel(excel_filename,\\n                      keep_default_na=False,    # Preserve empty cells as empty strings\\n                      na_filter=False)          # Don\\'t convert strings like \\'NA\\' to NaN\\n\\n    # Save to CSV with all data intact\\n    df.to_csv(csv_filename,\\n              index=False,           # Don\\'t save row indices\\n              encoding=\\'utf-8\\')      # Use UTF-8 encoding for special characters\\n\\n    print(f\"âœ… Converted {excel_filename} â†’ {csv_filename}\")\\n    print(f\"   Shape: {df.shape[0]} rows Ã— {df.shape[1]} columns\")\\n    return df\\n\\n# Convert all three files\\ninternal_df = excel_to_csv_safe(\"Internal_Bank_Dataset.xlsx\", \"Internal_Bank_Dataset.csv\")\\nexternal_df = excel_to_csv_safe(\"External_Cibil_Dataset.xlsx\", \"External_Cibil_Dataset.csv\")\\nunseen_df = excel_to_csv_safe(\"Unseen_Dataset.xlsx\", \"Unseen_Dataset.csv\")\\n\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "# Convert Excel files to CSV while preserving all data\n",
    "def excel_to_csv_safe(excel_filename, csv_filename):\n",
    "    \"\"\"\n",
    "    Convert Excel to CSV without losing data\n",
    "    \"\"\"\n",
    "    # Read Excel with all data preserved\n",
    "    df = pd.read_excel(excel_filename,\n",
    "                      keep_default_na=False,    # Preserve empty cells as empty strings\n",
    "                      na_filter=False)          # Don't convert strings like 'NA' to NaN\n",
    "\n",
    "    # Save to CSV with all data intact\n",
    "    df.to_csv(csv_filename,\n",
    "              index=False,           # Don't save row indices\n",
    "              encoding='utf-8')      # Use UTF-8 encoding for special characters\n",
    "\n",
    "    print(f\"âœ… Converted {excel_filename} â†’ {csv_filename}\")\n",
    "    print(f\"   Shape: {df.shape[0]} rows Ã— {df.shape[1]} columns\")\n",
    "    return df\n",
    "\n",
    "# Convert all three files\n",
    "internal_df = excel_to_csv_safe(\"Internal_Bank_Dataset.xlsx\", \"Internal_Bank_Dataset.csv\")\n",
    "external_df = excel_to_csv_safe(\"External_Cibil_Dataset.xlsx\", \"External_Cibil_Dataset.csv\")\n",
    "unseen_df = excel_to_csv_safe(\"Unseen_Dataset.xlsx\", \"Unseen_Dataset.csv\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "maOx63xwYjhc",
    "outputId": "6dd3ceae-e013-47af-9f32-bd6eceed6d31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n# Verify the conversion preserved all data\\ndef verify_conversion(excel_file, csv_file):\\n    \"\"\"\\n    Verify that CSV contains the same data as Excel\\n    \"\"\"\\n    excel_df = pd.read_excel(excel_file, keep_default_na=False, na_filter=False)\\n    csv_df = pd.read_csv(csv_file, keep_default_na=False, na_filter=False)\\n\\n    print(f\"ðŸ“Š {excel_file} vs {csv_file}:\")\\n    print(f\"   Excel shape: {excel_df.shape}\")\\n    print(f\"   CSV shape: {csv_df.shape}\")\\n    print(f\"   Data identical: {excel_df.equals(csv_df)}\")\\n    print()\\n\\n# Verify all conversions\\nverify_conversion(\"Internal_Bank_Dataset.xlsx\", \"Internal_Bank_Dataset.csv\")\\nverify_conversion(\"External_Cibil_Dataset.xlsx\", \"External_Cibil_Dataset.csv\")\\nverify_conversion(\"Unseen_Dataset.xlsx\", \"Unseen_Dataset.csv\")\\n\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "# Verify the conversion preserved all data\n",
    "def verify_conversion(excel_file, csv_file):\n",
    "    \"\"\"\n",
    "    Verify that CSV contains the same data as Excel\n",
    "    \"\"\"\n",
    "    excel_df = pd.read_excel(excel_file, keep_default_na=False, na_filter=False)\n",
    "    csv_df = pd.read_csv(csv_file, keep_default_na=False, na_filter=False)\n",
    "\n",
    "    print(f\"ðŸ“Š {excel_file} vs {csv_file}:\")\n",
    "    print(f\"   Excel shape: {excel_df.shape}\")\n",
    "    print(f\"   CSV shape: {csv_df.shape}\")\n",
    "    print(f\"   Data identical: {excel_df.equals(csv_df)}\")\n",
    "    print()\n",
    "\n",
    "# Verify all conversions\n",
    "verify_conversion(\"Internal_Bank_Dataset.xlsx\", \"Internal_Bank_Dataset.csv\")\n",
    "verify_conversion(\"External_Cibil_Dataset.xlsx\", \"External_Cibil_Dataset.csv\")\n",
    "verify_conversion(\"Unseen_Dataset.xlsx\", \"Unseen_Dataset.csv\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2SyuKZhZyN2"
   },
   "source": [
    "**Initial Validation & Sampling**\n",
    "\n",
    "- Display 10 random rows from each dataset using .sample(10).\n",
    "\n",
    "- Purpose: quick sanity check to verify file structure, values, and column alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIfbw_rPkbNy",
    "outputId": "feca078c-10c4-49d9-c02e-2bcaea6715b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Bank Dataset:\n",
      "       PROSPECTID  Total_TL  Tot_Closed_TL  Tot_Active_TL  \\\n",
      "15246       15247         3              2              1   \n",
      "18556       18557         1              1              0   \n",
      "4626         4627         2              0              2   \n",
      "41997       41998         2              0              2   \n",
      "29626       29627         1              0              1   \n",
      "40044       40045        10              5              5   \n",
      "23764       23765         2              0              2   \n",
      "31781       31782         6              3              3   \n",
      "25268       25269         1              0              1   \n",
      "2210         2211         1              1              0   \n",
      "\n",
      "       Total_TL_opened_L6M  Tot_TL_closed_L6M  pct_tl_open_L6M  \\\n",
      "15246                    0                  0            0.000   \n",
      "18556                    0                  0            0.000   \n",
      "4626                     0                  0            0.000   \n",
      "41997                    0                  0            0.000   \n",
      "29626                    0                  0            0.000   \n",
      "40044                    2                  3            0.200   \n",
      "23764                    0                  0            0.000   \n",
      "31781                    1                  0            0.167   \n",
      "25268                    1                  0            1.000   \n",
      "2210                     0                  0            0.000   \n",
      "\n",
      "       pct_tl_closed_L6M  pct_active_tl  pct_closed_tl  ...  CC_TL  \\\n",
      "15246                0.0          0.333          0.667  ...      0   \n",
      "18556                0.0          0.000          1.000  ...      0   \n",
      "4626                 0.0          1.000          0.000  ...      0   \n",
      "41997                0.0          1.000          0.000  ...      0   \n",
      "29626                0.0          1.000          0.000  ...      0   \n",
      "40044                0.3          0.500          0.500  ...      0   \n",
      "23764                0.0          1.000          0.000  ...      1   \n",
      "31781                0.0          0.500          0.500  ...      0   \n",
      "25268                0.0          1.000          0.000  ...      0   \n",
      "2210                 0.0          0.000          1.000  ...      0   \n",
      "\n",
      "       Consumer_TL  Gold_TL  Home_TL  PL_TL  Secured_TL  Unsecured_TL  \\\n",
      "15246            0        0        0      0           2             1   \n",
      "18556            0        0        0      0           1             0   \n",
      "4626             0        0        0      0           2             0   \n",
      "41997            2        0        0      0           0             2   \n",
      "29626            0        0        0      0           1             0   \n",
      "40044            3        0        0      5           1             9   \n",
      "23764            0        0        0      0           0             2   \n",
      "31781            1        3        0      0           4             2   \n",
      "25268            1        0        0      0           0             1   \n",
      "2210             0        1        0      0           1             0   \n",
      "\n",
      "       Other_TL  Age_Oldest_TL  Age_Newest_TL  \n",
      "15246         1             62             41  \n",
      "18556         0             33             33  \n",
      "4626          0             52             19  \n",
      "41997         0              8              7  \n",
      "29626         0             31             31  \n",
      "40044         1             32              2  \n",
      "23764         1            108             54  \n",
      "31781         1             43              6  \n",
      "25268         0              2              2  \n",
      "2210          0             70             70  \n",
      "\n",
      "[10 rows x 26 columns] \n",
      "\n",
      "External Cibil Dataset:\n",
      "       PROSPECTID  time_since_recent_payment  time_since_first_deliquency  \\\n",
      "22612       22613                         59                           14   \n",
      "35755       35756                        267                       -99999   \n",
      "45097       45098                         50                            7   \n",
      "12689       12690                         42                       -99999   \n",
      "4032         4033                       1073                           27   \n",
      "3506         3507                        238                           13   \n",
      "24381       24382                     -99999                       -99999   \n",
      "4788         4789                        136                       -99999   \n",
      "20943       20944                        784                       -99999   \n",
      "44946       44947                         62                       -99999   \n",
      "\n",
      "       time_since_recent_deliquency  num_times_delinquent  \\\n",
      "22612                            14                     1   \n",
      "35755                        -99999                     0   \n",
      "45097                             6                     2   \n",
      "12689                        -99999                     0   \n",
      "4032                             23                     5   \n",
      "3506                             12                     2   \n",
      "24381                        -99999                     0   \n",
      "4788                         -99999                     0   \n",
      "20943                        -99999                     0   \n",
      "44946                        -99999                     0   \n",
      "\n",
      "       max_delinquency_level  max_recent_level_of_deliq  num_deliq_6mts  \\\n",
      "22612                     28                         28               0   \n",
      "35755                 -99999                          0               0   \n",
      "45097                     28                         28               0   \n",
      "12689                 -99999                          0               0   \n",
      "4032                      30                         30               0   \n",
      "3506                      34                          4               0   \n",
      "24381                 -99999                          0               0   \n",
      "4788                  -99999                          0               0   \n",
      "20943                 -99999                          0               0   \n",
      "44946                 -99999                          0               0   \n",
      "\n",
      "       num_deliq_12mts  num_deliq_6_12mts  ...  pct_CC_enq_L6m_of_L12m  \\\n",
      "22612                0                  0  ...                     0.0   \n",
      "35755                0                  0  ...                     0.0   \n",
      "45097                2                  2  ...                     0.0   \n",
      "12689                0                  0  ...                     0.0   \n",
      "4032                 0                  0  ...                     0.0   \n",
      "3506                 0                  0  ...                     0.0   \n",
      "24381                0                  0  ...                     0.0   \n",
      "4788                 0                  0  ...                     0.0   \n",
      "20943                0                  0  ...                     0.0   \n",
      "44946                0                  0  ...                     0.0   \n",
      "\n",
      "       pct_PL_enq_L6m_of_ever  pct_CC_enq_L6m_of_ever  \\\n",
      "22612                     1.0                     0.0   \n",
      "35755                     0.0                     0.0   \n",
      "45097                     0.0                     0.0   \n",
      "12689                     0.0                     0.0   \n",
      "4032                      0.0                     0.0   \n",
      "3506                      0.0                     0.0   \n",
      "24381                     0.0                     0.0   \n",
      "4788                      0.0                     0.0   \n",
      "20943                     0.0                     0.0   \n",
      "44946                     0.0                     0.0   \n",
      "\n",
      "       max_unsec_exposure_inPct  HL_Flag  GL_Flag  last_prod_enq2  \\\n",
      "22612                -99999.000        1        0    ConsumerLoan   \n",
      "35755                -99999.000        0        0    ConsumerLoan   \n",
      "45097                     1.633        0        0    ConsumerLoan   \n",
      "12689                -99999.000        0        0          others   \n",
      "4032                      8.333        0        0              PL   \n",
      "3506                 -99999.000        1        1              PL   \n",
      "24381                     0.900        0        0    ConsumerLoan   \n",
      "4788                 -99999.000        1        0          others   \n",
      "20943                -99999.000        0        0              CC   \n",
      "44946                     3.849        0        0          others   \n",
      "\n",
      "       first_prod_enq2  Credit_Score  Approved_Flag  \n",
      "22612     ConsumerLoan           659             P3  \n",
      "35755     ConsumerLoan           691             P2  \n",
      "45097     ConsumerLoan           664             P3  \n",
      "12689           others           688             P2  \n",
      "4032            others           691             P2  \n",
      "3506            others           750             P1  \n",
      "24381     ConsumerLoan           656             P4  \n",
      "4788            others           690             P2  \n",
      "20943               CC           692             P2  \n",
      "44946           others           686             P2  \n",
      "\n",
      "[10 rows x 62 columns] \n",
      "\n",
      "Unseen Dataset:\n",
      "    pct_tl_open_L6M  pct_tl_closed_L6M  Tot_TL_closed_L12M  \\\n",
      "83            0.000               0.00                   0   \n",
      "21            0.667               0.00                   0   \n",
      "75            0.500               0.00                   0   \n",
      "15            0.000               0.20                   1   \n",
      "81            0.130               0.13                   4   \n",
      "16            0.000               1.00                   1   \n",
      "95            0.000               0.00                   0   \n",
      "33            0.000               0.00                   0   \n",
      "44            0.600               0.00                   0   \n",
      "76            0.500               0.50                   1   \n",
      "\n",
      "    pct_tl_closed_L12M  Tot_Missed_Pmnt  CC_TL  Home_TL  PL_TL  Secured_TL  \\\n",
      "83               0.000                0      0        0      0           6   \n",
      "21               0.000                2      0        0      0           0   \n",
      "75               0.000                1      0        0      0           1   \n",
      "15               0.200                1      0        0      1           3   \n",
      "81               0.174                2      0        0      1          19   \n",
      "16               1.000                0      0        0      0           1   \n",
      "95               0.000                0      0        0      1           1   \n",
      "33               0.000                0      0        0      0           1   \n",
      "44               0.000                1      0        0      2           0   \n",
      "76               0.500                1      0        0      2           0   \n",
      "\n",
      "    Unsecured_TL  ...  PL_Flag  pct_PL_enq_L6m_of_ever  \\\n",
      "83             0  ...        0                   0.000   \n",
      "21             3  ...        0                   0.000   \n",
      "75             3  ...        0                   0.000   \n",
      "15             2  ...        1                   0.000   \n",
      "81             4  ...        1                   0.000   \n",
      "16             0  ...        0                   0.000   \n",
      "95             5  ...        1                   0.000   \n",
      "33             0  ...        0                   0.000   \n",
      "44             5  ...        1                   0.750   \n",
      "76             2  ...        1                   0.333   \n",
      "\n",
      "    pct_CC_enq_L6m_of_ever  HL_Flag  GL_Flag  MARITALSTATUS       EDUCATION  \\\n",
      "83                     0.0        1        0        Married  UNDER GRADUATE   \n",
      "21                     0.0        0        0         Single        GRADUATE   \n",
      "75                     0.0        0        0        Married            12TH   \n",
      "15                     0.0        0        0        Married  UNDER GRADUATE   \n",
      "81                     0.0        1        0        Married        GRADUATE   \n",
      "16                     0.0        0        0         Single        GRADUATE   \n",
      "95                     0.0        0        0        Married        GRADUATE   \n",
      "33                     0.0        0        0        Married            12TH   \n",
      "44                     0.0        0        0         Single  UNDER GRADUATE   \n",
      "76                     0.0        0        0        Married        GRADUATE   \n",
      "\n",
      "    GENDER  last_prod_enq2  first_prod_enq2  \n",
      "83       M              AL               AL  \n",
      "21       M          others               CC  \n",
      "75       M          others     ConsumerLoan  \n",
      "15       F              PL           others  \n",
      "81       M    ConsumerLoan     ConsumerLoan  \n",
      "16       M    ConsumerLoan           others  \n",
      "95       M    ConsumerLoan           others  \n",
      "33       M          others           others  \n",
      "44       M              PL     ConsumerLoan  \n",
      "76       M              PL               PL  \n",
      "\n",
      "[10 rows x 42 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display 10 random records for initial validation\n",
    "\n",
    "print(\"Internal Bank Dataset:\")\n",
    "print(internal_df.sample(10), \"\\n\")\n",
    "\n",
    "print(\"External Cibil Dataset:\")\n",
    "print(external_df.sample(10), \"\\n\")\n",
    "\n",
    "print(\"Unseen Dataset:\")\n",
    "print(unseen_df.sample(10), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhr5G1qJq3gU"
   },
   "source": [
    "# **Check Columns and Basic Dataset Info**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ox8ng5fyaDbp"
   },
   "source": [
    "**Dataset Structure and Statistics**\n",
    "\n",
    "- View column names and dataset metadata.\n",
    "\n",
    "- Use .describe() for summary statistics and .info() for column types and null counts.\n",
    "\n",
    "- Purpose: understand schema, distributions, and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWE1fTkPkviU",
    "outputId": "4446628d-60c5-41b1-ee77-159d0213e334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal columns: ['PROSPECTID', 'Total_TL', 'Tot_Closed_TL', 'Tot_Active_TL', 'Total_TL_opened_L6M', 'Tot_TL_closed_L6M', 'pct_tl_open_L6M', 'pct_tl_closed_L6M', 'pct_active_tl', 'pct_closed_tl', 'Total_TL_opened_L12M', 'Tot_TL_closed_L12M', 'pct_tl_open_L12M', 'pct_tl_closed_L12M', 'Tot_Missed_Pmnt', 'Auto_TL', 'CC_TL', 'Consumer_TL', 'Gold_TL', 'Home_TL', 'PL_TL', 'Secured_TL', 'Unsecured_TL', 'Other_TL', 'Age_Oldest_TL', 'Age_Newest_TL']\n",
      "External columns: ['PROSPECTID', 'time_since_recent_payment', 'time_since_first_deliquency', 'time_since_recent_deliquency', 'num_times_delinquent', 'max_delinquency_level', 'max_recent_level_of_deliq', 'num_deliq_6mts', 'num_deliq_12mts', 'num_deliq_6_12mts', 'max_deliq_6mts', 'max_deliq_12mts', 'num_times_30p_dpd', 'num_times_60p_dpd', 'num_std', 'num_std_6mts', 'num_std_12mts', 'num_sub', 'num_sub_6mts', 'num_sub_12mts', 'num_dbt', 'num_dbt_6mts', 'num_dbt_12mts', 'num_lss', 'num_lss_6mts', 'num_lss_12mts', 'recent_level_of_deliq', 'tot_enq', 'CC_enq', 'CC_enq_L6m', 'CC_enq_L12m', 'PL_enq', 'PL_enq_L6m', 'PL_enq_L12m', 'time_since_recent_enq', 'enq_L12m', 'enq_L6m', 'enq_L3m', 'MARITALSTATUS', 'EDUCATION', 'AGE', 'GENDER', 'NETMONTHLYINCOME', 'Time_With_Curr_Empr', 'pct_of_active_TLs_ever', 'pct_opened_TLs_L6m_of_L12m', 'pct_currentBal_all_TL', 'CC_utilization', 'CC_Flag', 'PL_utilization', 'PL_Flag', 'pct_PL_enq_L6m_of_L12m', 'pct_CC_enq_L6m_of_L12m', 'pct_PL_enq_L6m_of_ever', 'pct_CC_enq_L6m_of_ever', 'max_unsec_exposure_inPct', 'HL_Flag', 'GL_Flag', 'last_prod_enq2', 'first_prod_enq2', 'Credit_Score', 'Approved_Flag']\n",
      "Internal Dataset :-\n",
      "         PROSPECTID      Total_TL  Tot_Closed_TL  Tot_Active_TL  \\\n",
      "count  51336.000000  51336.000000   51336.000000   51336.000000   \n",
      "mean   25668.500000      4.858598       2.770415       2.088184   \n",
      "std    14819.571046      7.177116       5.941680       2.290774   \n",
      "min        1.000000      1.000000       0.000000       0.000000   \n",
      "25%    12834.750000      1.000000       0.000000       1.000000   \n",
      "50%    25668.500000      2.000000       1.000000       1.000000   \n",
      "75%    38502.250000      5.000000       3.000000       3.000000   \n",
      "max    51336.000000    235.000000     216.000000      47.000000   \n",
      "\n",
      "       Total_TL_opened_L6M  Tot_TL_closed_L6M  pct_tl_open_L6M  \\\n",
      "count         51336.000000       51336.000000     51336.000000   \n",
      "mean              0.736754           0.428919         0.184574   \n",
      "std               1.296717           0.989972         0.297414   \n",
      "min               0.000000           0.000000         0.000000   \n",
      "25%               0.000000           0.000000         0.000000   \n",
      "50%               0.000000           0.000000         0.000000   \n",
      "75%               1.000000           1.000000         0.308000   \n",
      "max              27.000000          19.000000         1.000000   \n",
      "\n",
      "       pct_tl_closed_L6M  pct_active_tl  pct_closed_tl  ...         CC_TL  \\\n",
      "count       51336.000000   51336.000000   51336.000000  ...  51336.000000   \n",
      "mean            0.089095       0.577542       0.422458  ...      0.124981   \n",
      "std             0.205635       0.379867       0.379867  ...      0.505201   \n",
      "min             0.000000       0.000000       0.000000  ...      0.000000   \n",
      "25%             0.000000       0.250000       0.000000  ...      0.000000   \n",
      "50%             0.000000       0.556000       0.444000  ...      0.000000   \n",
      "75%             0.053000       1.000000       0.750000  ...      0.000000   \n",
      "max             1.000000       1.000000       1.000000  ...     27.000000   \n",
      "\n",
      "        Consumer_TL       Gold_TL       Home_TL         PL_TL    Secured_TL  \\\n",
      "count  51336.000000  51336.000000  51336.000000  51336.000000  51336.000000   \n",
      "mean       1.136084      1.561847      0.070146      0.282511      2.844904   \n",
      "std        2.227997      5.376434      0.340861      0.858168      6.187177   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "50%        0.000000      0.000000      0.000000      0.000000      1.000000   \n",
      "75%        1.000000      1.000000      0.000000      0.000000      3.000000   \n",
      "max       41.000000    235.000000     10.000000     29.000000    235.000000   \n",
      "\n",
      "       Unsecured_TL      Other_TL  Age_Oldest_TL  Age_Newest_TL  \n",
      "count  51336.000000  51336.000000   51336.000000   51336.000000  \n",
      "mean       2.013694      1.089762     -32.575639     -62.149525  \n",
      "std        3.198322      2.417496    2791.869609    2790.818622  \n",
      "min        0.000000      0.000000  -99999.000000  -99999.000000  \n",
      "25%        0.000000      0.000000      14.000000       4.000000  \n",
      "50%        1.000000      0.000000      33.000000       8.000000  \n",
      "75%        2.000000      1.000000      64.000000      17.000000  \n",
      "max       55.000000     80.000000     392.000000     392.000000  \n",
      "\n",
      "[8 rows x 26 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51336 entries, 0 to 51335\n",
      "Data columns (total 26 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   PROSPECTID            51336 non-null  int64  \n",
      " 1   Total_TL              51336 non-null  int64  \n",
      " 2   Tot_Closed_TL         51336 non-null  int64  \n",
      " 3   Tot_Active_TL         51336 non-null  int64  \n",
      " 4   Total_TL_opened_L6M   51336 non-null  int64  \n",
      " 5   Tot_TL_closed_L6M     51336 non-null  int64  \n",
      " 6   pct_tl_open_L6M       51336 non-null  float64\n",
      " 7   pct_tl_closed_L6M     51336 non-null  float64\n",
      " 8   pct_active_tl         51336 non-null  float64\n",
      " 9   pct_closed_tl         51336 non-null  float64\n",
      " 10  Total_TL_opened_L12M  51336 non-null  int64  \n",
      " 11  Tot_TL_closed_L12M    51336 non-null  int64  \n",
      " 12  pct_tl_open_L12M      51336 non-null  float64\n",
      " 13  pct_tl_closed_L12M    51336 non-null  float64\n",
      " 14  Tot_Missed_Pmnt       51336 non-null  int64  \n",
      " 15  Auto_TL               51336 non-null  int64  \n",
      " 16  CC_TL                 51336 non-null  int64  \n",
      " 17  Consumer_TL           51336 non-null  int64  \n",
      " 18  Gold_TL               51336 non-null  int64  \n",
      " 19  Home_TL               51336 non-null  int64  \n",
      " 20  PL_TL                 51336 non-null  int64  \n",
      " 21  Secured_TL            51336 non-null  int64  \n",
      " 22  Unsecured_TL          51336 non-null  int64  \n",
      " 23  Other_TL              51336 non-null  int64  \n",
      " 24  Age_Oldest_TL         51336 non-null  int64  \n",
      " 25  Age_Newest_TL         51336 non-null  int64  \n",
      "dtypes: float64(6), int64(20)\n",
      "memory usage: 10.2 MB\n",
      "None\n",
      "External Dataset :-\n",
      "         PROSPECTID  time_since_recent_payment  time_since_first_deliquency  \\\n",
      "count  51336.000000               51336.000000                 51336.000000   \n",
      "mean   25668.500000               -8129.961314                -70020.091320   \n",
      "std    14819.571046               27749.328514                 45823.312757   \n",
      "min        1.000000              -99999.000000                -99999.000000   \n",
      "25%    12834.750000                  46.000000                -99999.000000   \n",
      "50%    25668.500000                  70.000000                -99999.000000   \n",
      "75%    38502.250000                 161.000000                     8.000000   \n",
      "max    51336.000000                6065.000000                    35.000000   \n",
      "\n",
      "       time_since_recent_deliquency  num_times_delinquent  \\\n",
      "count                  51336.000000          51336.000000   \n",
      "mean                  -70022.375838              1.573749   \n",
      "std                    45819.820741              4.165012   \n",
      "min                   -99999.000000              0.000000   \n",
      "25%                   -99999.000000              0.000000   \n",
      "50%                   -99999.000000              0.000000   \n",
      "75%                        3.000000              1.000000   \n",
      "max                       35.000000             74.000000   \n",
      "\n",
      "       max_delinquency_level  max_recent_level_of_deliq  num_deliq_6mts  \\\n",
      "count           51336.000000               51336.000000    51336.000000   \n",
      "mean           -70003.987085                  13.521953        0.184977   \n",
      "std             45847.976100                  53.336976        0.710240   \n",
      "min            -99999.000000                   0.000000        0.000000   \n",
      "25%            -99999.000000                   0.000000        0.000000   \n",
      "50%            -99999.000000                   0.000000        0.000000   \n",
      "75%                15.000000                  10.000000        0.000000   \n",
      "max               900.000000                 900.000000       12.000000   \n",
      "\n",
      "       num_deliq_12mts  num_deliq_6_12mts  ...  PL_utilization       PL_Flag  \\\n",
      "count     51336.000000       51336.000000  ...    51336.000000  51336.000000   \n",
      "mean          0.480053           0.295076  ...   -86556.225194      0.167874   \n",
      "std           1.522210           1.027471  ...    34111.414750      0.373758   \n",
      "min           0.000000           0.000000  ...   -99999.000000      0.000000   \n",
      "25%           0.000000           0.000000  ...   -99999.000000      0.000000   \n",
      "50%           0.000000           0.000000  ...   -99999.000000      0.000000   \n",
      "75%           0.000000           0.000000  ...   -99999.000000      0.000000   \n",
      "max          28.000000          20.000000  ...        1.708000      1.000000   \n",
      "\n",
      "       pct_PL_enq_L6m_of_L12m  pct_CC_enq_L6m_of_L12m  pct_PL_enq_L6m_of_ever  \\\n",
      "count            51336.000000            51336.000000            51336.000000   \n",
      "mean                 0.190414                0.065182                0.170492   \n",
      "std                  0.376218                0.235706                0.350209   \n",
      "min                  0.000000                0.000000                0.000000   \n",
      "25%                  0.000000                0.000000                0.000000   \n",
      "50%                  0.000000                0.000000                0.000000   \n",
      "75%                  0.000000                0.000000                0.000000   \n",
      "max                  1.000000                1.000000                1.000000   \n",
      "\n",
      "       pct_CC_enq_L6m_of_ever  max_unsec_exposure_inPct       HL_Flag  \\\n",
      "count            51336.000000              51336.000000  51336.000000   \n",
      "mean                 0.056302             -45127.943635      0.271116   \n",
      "std                  0.213506              49795.784556      0.444540   \n",
      "min                  0.000000             -99999.000000      0.000000   \n",
      "25%                  0.000000             -99999.000000      0.000000   \n",
      "50%                  0.000000                  0.333000      0.000000   \n",
      "75%                  0.000000                  2.164250      1.000000   \n",
      "max                  1.000000             173800.000000      1.000000   \n",
      "\n",
      "            GL_Flag  Credit_Score  \n",
      "count  51336.000000  51336.000000  \n",
      "mean       0.052887    679.859222  \n",
      "std        0.223810     20.502764  \n",
      "min        0.000000    469.000000  \n",
      "25%        0.000000    669.000000  \n",
      "50%        0.000000    680.000000  \n",
      "75%        0.000000    691.000000  \n",
      "max        1.000000    811.000000  \n",
      "\n",
      "[8 rows x 56 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51336 entries, 0 to 51335\n",
      "Data columns (total 62 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   PROSPECTID                    51336 non-null  int64  \n",
      " 1   time_since_recent_payment     51336 non-null  int64  \n",
      " 2   time_since_first_deliquency   51336 non-null  int64  \n",
      " 3   time_since_recent_deliquency  51336 non-null  int64  \n",
      " 4   num_times_delinquent          51336 non-null  int64  \n",
      " 5   max_delinquency_level         51336 non-null  int64  \n",
      " 6   max_recent_level_of_deliq     51336 non-null  int64  \n",
      " 7   num_deliq_6mts                51336 non-null  int64  \n",
      " 8   num_deliq_12mts               51336 non-null  int64  \n",
      " 9   num_deliq_6_12mts             51336 non-null  int64  \n",
      " 10  max_deliq_6mts                51336 non-null  int64  \n",
      " 11  max_deliq_12mts               51336 non-null  int64  \n",
      " 12  num_times_30p_dpd             51336 non-null  int64  \n",
      " 13  num_times_60p_dpd             51336 non-null  int64  \n",
      " 14  num_std                       51336 non-null  int64  \n",
      " 15  num_std_6mts                  51336 non-null  int64  \n",
      " 16  num_std_12mts                 51336 non-null  int64  \n",
      " 17  num_sub                       51336 non-null  int64  \n",
      " 18  num_sub_6mts                  51336 non-null  int64  \n",
      " 19  num_sub_12mts                 51336 non-null  int64  \n",
      " 20  num_dbt                       51336 non-null  int64  \n",
      " 21  num_dbt_6mts                  51336 non-null  int64  \n",
      " 22  num_dbt_12mts                 51336 non-null  int64  \n",
      " 23  num_lss                       51336 non-null  int64  \n",
      " 24  num_lss_6mts                  51336 non-null  int64  \n",
      " 25  num_lss_12mts                 51336 non-null  int64  \n",
      " 26  recent_level_of_deliq         51336 non-null  int64  \n",
      " 27  tot_enq                       51336 non-null  int64  \n",
      " 28  CC_enq                        51336 non-null  int64  \n",
      " 29  CC_enq_L6m                    51336 non-null  int64  \n",
      " 30  CC_enq_L12m                   51336 non-null  int64  \n",
      " 31  PL_enq                        51336 non-null  int64  \n",
      " 32  PL_enq_L6m                    51336 non-null  int64  \n",
      " 33  PL_enq_L12m                   51336 non-null  int64  \n",
      " 34  time_since_recent_enq         51336 non-null  int64  \n",
      " 35  enq_L12m                      51336 non-null  int64  \n",
      " 36  enq_L6m                       51336 non-null  int64  \n",
      " 37  enq_L3m                       51336 non-null  int64  \n",
      " 38  MARITALSTATUS                 51336 non-null  object \n",
      " 39  EDUCATION                     51336 non-null  object \n",
      " 40  AGE                           51336 non-null  int64  \n",
      " 41  GENDER                        51336 non-null  object \n",
      " 42  NETMONTHLYINCOME              51336 non-null  int64  \n",
      " 43  Time_With_Curr_Empr           51336 non-null  int64  \n",
      " 44  pct_of_active_TLs_ever        51336 non-null  float64\n",
      " 45  pct_opened_TLs_L6m_of_L12m    51336 non-null  float64\n",
      " 46  pct_currentBal_all_TL         51336 non-null  float64\n",
      " 47  CC_utilization                51336 non-null  float64\n",
      " 48  CC_Flag                       51336 non-null  int64  \n",
      " 49  PL_utilization                51336 non-null  float64\n",
      " 50  PL_Flag                       51336 non-null  int64  \n",
      " 51  pct_PL_enq_L6m_of_L12m        51336 non-null  float64\n",
      " 52  pct_CC_enq_L6m_of_L12m        51336 non-null  float64\n",
      " 53  pct_PL_enq_L6m_of_ever        51336 non-null  float64\n",
      " 54  pct_CC_enq_L6m_of_ever        51336 non-null  float64\n",
      " 55  max_unsec_exposure_inPct      51336 non-null  float64\n",
      " 56  HL_Flag                       51336 non-null  int64  \n",
      " 57  GL_Flag                       51336 non-null  int64  \n",
      " 58  last_prod_enq2                51336 non-null  object \n",
      " 59  first_prod_enq2               51336 non-null  object \n",
      " 60  Credit_Score                  51336 non-null  int64  \n",
      " 61  Approved_Flag                 51336 non-null  object \n",
      "dtypes: float64(10), int64(46), object(6)\n",
      "memory usage: 24.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Internal columns:\", internal_df.columns.tolist())\n",
    "print(\"External columns:\", external_df.columns.tolist())\n",
    "\n",
    "print(\"Internal Dataset :-\")\n",
    "print(internal_df.describe())\n",
    "print(internal_df.info())\n",
    "\n",
    "print(\"External Dataset :-\")\n",
    "print(external_df.describe())\n",
    "print(external_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2z_70A-jxQH7"
   },
   "source": [
    "# **Define Data Paths and Merging Setup**\n",
    "Set path and Recheck data after merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3vY0bIZCxJS6"
   },
   "outputs": [],
   "source": [
    "# define merge key and paths to datasets\n",
    "\n",
    "merge_key = \"PROSPECTID\"\n",
    "\n",
    "internal_path = Path(\"Internal_Bank_Dataset.csv\")\n",
    "external_path = Path(\"External_Cibil_Dataset.csv\")\n",
    "unseen_path = Path(\"Unseen_Dataset.csv\")\n",
    "merged_save_path = Path(\"merged_internal_external.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XQ49ZdSMxiU7"
   },
   "outputs": [],
   "source": [
    "# Check if merge key exists in both datasets\n",
    "\n",
    "if merge_key not in internal_df.columns or merge_key not in external_df.columns:\n",
    "    raise KeyError(f\"Merge key '{merge_key}' missing in one of the files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWaxxhpkxzrJ"
   },
   "source": [
    "# **Dataset Shape and Duplicate Checks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTyMVsNBd0Ve"
   },
   "source": [
    "**Duplicate Detection in Merge Key**\n",
    "\n",
    "- Detect duplicate PROSPECTIDs using .duplicated().sum().\n",
    "\n",
    "- Print sample duplicate IDs if they exist.\n",
    "\n",
    "- Purpose: prevents one-to-many merges that could corrupt the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qc2G_4xNx2jM",
    "outputId": "8e5b09f2-744e-45ac-f6c0-2b11e13c66dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: internal: (51336, 26) external: (51336, 62) unseen: (100, 42)\n",
      "Duplicate PROSPECTID count -> internal: 0, external: 0\n"
     ]
    }
   ],
   "source": [
    "# Dataset shapes\n",
    "print(\"Shapes: internal:\", internal_df.shape, \"external:\", external_df.shape, \"unseen:\", unseen_df.shape)\n",
    "\n",
    "# Detect duplicates in merge key\n",
    "int_dup_count = internal_df[merge_key].duplicated().sum()\n",
    "ext_dup_count = external_df[merge_key].duplicated().sum()\n",
    "print(f\"Duplicate PROSPECTID count -> internal: {int_dup_count}, external: {ext_dup_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3MtQvhHzyDEq"
   },
   "outputs": [],
   "source": [
    "# Show sample duplicate PROSPECTID entries if exists\n",
    "\n",
    "if int_dup_count:\n",
    "    print(\"Sample duplicate PROSPECTIDs in internal:\\n\",\n",
    "          internal_df[internal_df[merge_key].duplicated()][merge_key].unique()[:10])\n",
    "if ext_dup_count:\n",
    "    print(\"Sample duplicate PROSPECTIDs in external:\\n\",\n",
    "          external_df[external_df[merge_key].duplicated()][merge_key].unique()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTEGymS9yH8Y"
   },
   "source": [
    "# **Data Cleaning and Merging**\n",
    "Replace Sentinel Values (-99999 as Sentinel as seen from sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "I_yDlm-NyGrS"
   },
   "outputs": [],
   "source": [
    "# replace sentinel with NaN for cleaning\n",
    "\n",
    "SENTINEL = -99999\n",
    "\n",
    "internal_df.replace(SENTINEL, np.nan, inplace=True)\n",
    "external_df.replace(SENTINEL, np.nan, inplace=True)\n",
    "unseen_df.replace(SENTINEL, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCjspDqCdkj3"
   },
   "source": [
    "**Inner Merge of Datasets**\n",
    "\n",
    "- Merge internal_df and external_df on PROSPECTID.\n",
    "\n",
    "- Use suffixes (_int, _ext) to differentiate overlapping columns.\n",
    "\n",
    "- Purpose: combine datasets only for common IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mAPYClq5yZge",
    "outputId": "6f6871d2-7353-4b6e-c704-6c17a9b93fbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged (inner) shape: (51336, 87)\n",
      "Merged columns example: ['PROSPECTID', 'Total_TL', 'Tot_Closed_TL', 'Tot_Active_TL', 'Total_TL_opened_L6M', 'Tot_TL_closed_L6M', 'pct_tl_open_L6M', 'pct_tl_closed_L6M', 'pct_active_tl', 'pct_closed_tl', 'Total_TL_opened_L12M', 'Tot_TL_closed_L12M', 'pct_tl_open_L12M', 'pct_tl_closed_L12M', 'Tot_Missed_Pmnt', 'Auto_TL', 'CC_TL', 'Consumer_TL', 'Gold_TL', 'Home_TL']\n",
      "Merged sample rows:\n",
      "       PROSPECTID  Total_TL  Tot_Closed_TL  Tot_Active_TL  \\\n",
      "16669       16670         2              2              0   \n",
      "29714       29715         1              0              1   \n",
      "7182         7183         3              1              2   \n",
      "3370         3371         2              0              2   \n",
      "34484       34485         1              0              1   \n",
      "15051       15052         6              3              3   \n",
      "24177       24178         5              4              1   \n",
      "20959       20960         2              0              2   \n",
      "21559       21560         3              0              3   \n",
      "13339       13340         2              1              1   \n",
      "\n",
      "       Total_TL_opened_L6M  Tot_TL_closed_L6M  pct_tl_open_L6M  \\\n",
      "16669                    0                  0              0.0   \n",
      "29714                    0                  0              0.0   \n",
      "7182                     0                  0              0.0   \n",
      "3370                     0                  0              0.0   \n",
      "34484                    1                  0              1.0   \n",
      "15051                    0                  0              0.0   \n",
      "24177                    0                  1              0.0   \n",
      "20959                    0                  0              0.0   \n",
      "21559                    0                  0              0.0   \n",
      "13339                    0                  1              0.0   \n",
      "\n",
      "       pct_tl_closed_L6M  pct_active_tl  pct_closed_tl  ...  \\\n",
      "16669                0.0          0.000          1.000  ...   \n",
      "29714                0.0          1.000          0.000  ...   \n",
      "7182                 0.0          0.667          0.333  ...   \n",
      "3370                 0.0          1.000          0.000  ...   \n",
      "34484                0.0          1.000          0.000  ...   \n",
      "15051                0.0          0.500          0.500  ...   \n",
      "24177                0.2          0.200          0.800  ...   \n",
      "20959                0.0          1.000          0.000  ...   \n",
      "21559                0.0          1.000          0.000  ...   \n",
      "13339                0.5          0.500          0.500  ...   \n",
      "\n",
      "       pct_CC_enq_L6m_of_L12m  pct_PL_enq_L6m_of_ever  pct_CC_enq_L6m_of_ever  \\\n",
      "16669                     0.0                     0.0                     0.0   \n",
      "29714                     0.0                     0.0                     0.0   \n",
      "7182                      0.0                     0.0                     0.0   \n",
      "3370                      0.0                     0.0                     0.0   \n",
      "34484                     0.0                     0.0                     0.0   \n",
      "15051                     0.0                     0.0                     0.0   \n",
      "24177                     0.0                     0.0                     0.0   \n",
      "20959                     0.0                     0.0                     0.0   \n",
      "21559                     0.0                     0.0                     0.0   \n",
      "13339                     0.0                     1.0                     0.0   \n",
      "\n",
      "       max_unsec_exposure_inPct  HL_Flag  GL_Flag  last_prod_enq2  \\\n",
      "16669                       NaN        1        0          others   \n",
      "29714                       NaN        0        0          others   \n",
      "7182                      2.667        1        0          others   \n",
      "3370                        NaN        0        0    ConsumerLoan   \n",
      "34484                     0.430        0        0    ConsumerLoan   \n",
      "15051                     6.780        1        0              PL   \n",
      "24177                       NaN        0        1              AL   \n",
      "20959                   180.858        0        0    ConsumerLoan   \n",
      "21559                     1.368        0        0          others   \n",
      "13339                    23.000        0        0          others   \n",
      "\n",
      "       first_prod_enq2  Credit_Score  Approved_Flag  \n",
      "16669           others           674             P2  \n",
      "29714           others           690             P2  \n",
      "7182            others           694             P2  \n",
      "3370            others           673             P2  \n",
      "34484     ConsumerLoan           664             P3  \n",
      "15051               PL           706             P1  \n",
      "24177               HL           693             P2  \n",
      "20959               CC           676             P2  \n",
      "21559     ConsumerLoan           686             P2  \n",
      "13339               AL           673             P2  \n",
      "\n",
      "[10 rows x 87 columns]\n",
      "Merged dataset saved to: merged_internal_external.csv\n"
     ]
    }
   ],
   "source": [
    "# perform inner merge\n",
    "merged_df = pd.merge(internal_df, external_df, on=merge_key, how=\"inner\", suffixes=(\"_int\", \"_ext\"))\n",
    "\n",
    "# output shape and sample columns\n",
    "print(\"Merged (inner) shape:\", merged_df.shape)\n",
    "print(\"Merged columns example:\", merged_df.columns.tolist()[:20])\n",
    "\n",
    "# show sample data\n",
    "print(\"Merged sample rows:\")\n",
    "print(merged_df.sample(10))\n",
    "\n",
    "# save merged dataset\n",
    "merged_df.to_csv(merged_save_path, index=False)\n",
    "print(\"Merged dataset saved to:\", merged_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4n998nvWyvCu"
   },
   "source": [
    "**Merge Indicator for Outer Join Validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jt9Vlq_Ya3lj"
   },
   "source": [
    "**Merge Indicator (Discrepancy Check)**\n",
    "\n",
    "- Perform an outer merge with _merge indicator.\n",
    "\n",
    "- Shows whether IDs exist in both datasets or only one.\n",
    "\n",
    "- Purpose: identify mismatched records and data coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tgAzBbkoyqSt",
    "outputId": "d3b4b819-a2dc-4428-effd-570b94a5ae5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge indicator counts (outer join):\n",
      "{'both': 51336, 'left_only': 0, 'right_only': 0}\n"
     ]
    }
   ],
   "source": [
    "# merge with indicator to check for discrepancies\n",
    "\n",
    "indicator = pd.merge(internal_df[[merge_key]], external_df[[merge_key]], on=merge_key, how=\"outer\", indicator=True)\n",
    "print(\"Merge indicator counts (outer join):\")\n",
    "print(indicator['_merge'].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeVqGoW2y3JO"
   },
   "source": [
    "# **Handling Unseen Dataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Y8mFIdPaqQ-"
   },
   "source": [
    "**Check PROSPECTID in Unseen Dataset**\n",
    "\n",
    " - If present, unseen can be merged later for predictions.\n",
    "\n",
    "- If absent, it is feature-only â†’ preprocessing pipeline must be applied separately.\n",
    "\n",
    "- Purpose: prepare unseen data path for model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aU30oU_Kyy3u",
    "outputId": "5ef62c2b-5fa5-4897-b28c-6d6602de9d64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unseen dataset does NOT contain PROSPECTID (contains only features). Keep unseen_df separate and apply same preprocessing pipeline before scoring.\n"
     ]
    }
   ],
   "source": [
    "# check PROSPECTID presence in unseen data\n",
    "\n",
    "if 'PROSPECTID' in unseen_df.columns:\n",
    "    print(\"Unseen dataset contains PROSPECTID. You can merge predictions on that key later.\")\n",
    "else:\n",
    "    print(\"Unseen dataset does NOT contain PROSPECTID (contains only features). Keep unseen_df separate and apply same preprocessing pipeline before scoring.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqd5F7Ws6jLI"
   },
   "source": [
    "âœ… **Summary**\n",
    "\n",
    "- Loaded raw datasets and inspected their structure.\n",
    "\n",
    "- Validated merge key existence and dataset integrity.\n",
    "\n",
    "- Handled duplicates and standardized missing values (NaN).\n",
    "\n",
    "- Merged datasets safely using PROSPECTID.\n",
    "\n",
    "- Checked discrepancies in coverage across internal and external IDs.\n",
    "\n",
    "- Prepared unseen dataset path for downstream prediction.\n",
    "\n",
    "This ensures a clean, consistent, and analysis-ready dataset for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28oMBOmrzW9u"
   },
   "source": [
    "# **Exploratory Data Analysis (EDA) & Visualization**\n",
    "Load the merged dataset for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "TZQsz67Ny-L2"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(merged_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6ohf3Akz89u"
   },
   "source": [
    "*Basic Dataset Overview*\n",
    "- Shape\n",
    "- Columns & Data Types\n",
    "- Target Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KhF2o-mH49gq"
   },
   "source": [
    "**Load and Inspect Data**\n",
    "\n",
    "- Purpose: Load the merged dataset and review its shape, column names, datatypes, and target class distribution.\n",
    "\n",
    "- Why: Ensures we understand schema and check if the target variable (Approved_Flag) is balanced or imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UikUtmpi0Cbn",
    "outputId": "765c35ae-c3e0-4e01-8336-50a52ce0030e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (51336, 87)\n",
      "\n",
      "Columns:\n",
      " Index(['PROSPECTID', 'Total_TL', 'Tot_Closed_TL', 'Tot_Active_TL',\n",
      "       'Total_TL_opened_L6M', 'Tot_TL_closed_L6M', 'pct_tl_open_L6M',\n",
      "       'pct_tl_closed_L6M', 'pct_active_tl', 'pct_closed_tl',\n",
      "       'Total_TL_opened_L12M', 'Tot_TL_closed_L12M', 'pct_tl_open_L12M',\n",
      "       'pct_tl_closed_L12M', 'Tot_Missed_Pmnt', 'Auto_TL', 'CC_TL',\n",
      "       'Consumer_TL', 'Gold_TL', 'Home_TL', 'PL_TL', 'Secured_TL',\n",
      "       'Unsecured_TL', 'Other_TL', 'Age_Oldest_TL', 'Age_Newest_TL',\n",
      "       'time_since_recent_payment', 'time_since_first_deliquency',\n",
      "       'time_since_recent_deliquency', 'num_times_delinquent',\n",
      "       'max_delinquency_level', 'max_recent_level_of_deliq', 'num_deliq_6mts',\n",
      "       'num_deliq_12mts', 'num_deliq_6_12mts', 'max_deliq_6mts',\n",
      "       'max_deliq_12mts', 'num_times_30p_dpd', 'num_times_60p_dpd', 'num_std',\n",
      "       'num_std_6mts', 'num_std_12mts', 'num_sub', 'num_sub_6mts',\n",
      "       'num_sub_12mts', 'num_dbt', 'num_dbt_6mts', 'num_dbt_12mts', 'num_lss',\n",
      "       'num_lss_6mts', 'num_lss_12mts', 'recent_level_of_deliq', 'tot_enq',\n",
      "       'CC_enq', 'CC_enq_L6m', 'CC_enq_L12m', 'PL_enq', 'PL_enq_L6m',\n",
      "       'PL_enq_L12m', 'time_since_recent_enq', 'enq_L12m', 'enq_L6m',\n",
      "       'enq_L3m', 'MARITALSTATUS', 'EDUCATION', 'AGE', 'GENDER',\n",
      "       'NETMONTHLYINCOME', 'Time_With_Curr_Empr', 'pct_of_active_TLs_ever',\n",
      "       'pct_opened_TLs_L6m_of_L12m', 'pct_currentBal_all_TL', 'CC_utilization',\n",
      "       'CC_Flag', 'PL_utilization', 'PL_Flag', 'pct_PL_enq_L6m_of_L12m',\n",
      "       'pct_CC_enq_L6m_of_L12m', 'pct_PL_enq_L6m_of_ever',\n",
      "       'pct_CC_enq_L6m_of_ever', 'max_unsec_exposure_inPct', 'HL_Flag',\n",
      "       'GL_Flag', 'last_prod_enq2', 'first_prod_enq2', 'Credit_Score',\n",
      "       'Approved_Flag'],\n",
      "      dtype='object')\n",
      "\n",
      "Data types:\n",
      " int64      46\n",
      "float64    35\n",
      "object      6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target variable distribution (Approved_Flag):\n",
      " Approved_Flag\n",
      "P2    32199\n",
      "P3     7452\n",
      "P4     5882\n",
      "P1     5803\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\\n\", df.columns)\n",
    "print(\"\\nData types:\\n\", df.dtypes.value_counts())\n",
    "\n",
    "print(\"\\nTarget variable distribution (Approved_Flag):\\n\", df['Approved_Flag'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKUbLEbF0MWC"
   },
   "source": [
    "# **Visualizations: Distributions and Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "OzcuRnGw0NJB"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      3\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mmatplotlib\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minline\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# set global plot style\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FhPopuQH5J4U"
   },
   "source": [
    "**Target Distribution Pie Chart**\n",
    "- Purpose: Visualize class balance between approved vs rejected applications.\n",
    "\n",
    "- Why: Class imbalance can strongly influence model performance and guide resampling strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "AI-ktsQJ0VHW",
    "outputId": "a0eb7de8-9cf5-4203-f3b7-ec4968bd1625"
   },
   "outputs": [],
   "source": [
    "# Target distribution pie chart\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "target_counts = df['Approved_Flag'].value_counts()\n",
    "plt.pie(target_counts.values, labels=target_counts.index, autopct='%1.1f%%')\n",
    "plt.title('Approval Flag Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DQLEdRw5aue"
   },
   "source": [
    "**Feature Distribution Histograms**\n",
    "- Purpose: Plot frequency distributions of key numeric features.\n",
    "\n",
    "- Why: Detect outliers, skewness, and common ranges in applicant characteristics.\n",
    "\n",
    "How:\n",
    "\n",
    "- Income is log-transformed to reduce skew.\n",
    "\n",
    "- Each plot highlights different applicant attributes (creditworthiness, income, age, credit activity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "bJVHRyXA0bfs",
    "outputId": "354be175-20cd-4cfc-a578-ba85cdb56335"
   },
   "outputs": [],
   "source": [
    "# Credit Score Distribution Histogram\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(df['Credit_Score'].dropna(), bins=50, color='skyblue', alpha=0.7)\n",
    "plt.xlabel('Credit Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Credit Score Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46Lfwq-n5tuv"
   },
   "source": [
    "**Missing Values Visualization**\n",
    "- Purpose: Identify top 20 columns with most missing values.\n",
    "\n",
    "- Why: Guides data cleaning and feature engineering strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "1zRXdG9Q0jhj",
    "outputId": "3856e3c7-e2ad-4b2c-d25f-435826b1ee3b"
   },
   "outputs": [],
   "source": [
    "# Net Monthly Income Distribution (Log Scale)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "income_clean = df['NETMONTHLYINCOME'].dropna()\n",
    "income_clean = income_clean[income_clean > 0]  # Filter positive values\n",
    "plt.hist(np.log10(income_clean), bins=50, color='lightgreen', alpha=0.7)\n",
    "plt.xlabel('Log10(Net Monthly Income)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Net Monthly Income Distribution (Log Scale)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "jdeD1sKr0qtz",
    "outputId": "a14aaf73-a32c-4205-801f-87ec46a0dcf5"
   },
   "outputs": [],
   "source": [
    "# Age Distribution Histogram\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(df['AGE'].dropna(), bins=50, color='orange', alpha=0.7)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Age Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "HhJBOEqy0tvc",
    "outputId": "b9d60de3-f6df-47cb-efad-70b1ab845f13"
   },
   "outputs": [],
   "source": [
    "# Total Trade Lines Histogram\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(df['Total_TL'].dropna(), bins=50, color='purple', alpha=0.7)\n",
    "plt.xlabel('Total Trade Lines')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Total Trade Lines Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 569
    },
    "id": "npYZ-Me4005c",
    "outputId": "f77b4184-3512-45a5-d23b-845cd655c52c"
   },
   "outputs": [],
   "source": [
    "# Missing Values Heatmap (Top 20 columns with most missing values)\n",
    "\n",
    "missing_data = df.isnull().sum().sort_values(ascending=False)[:20]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(missing_data.index, missing_data.values, color='grey')\n",
    "plt.xlabel('Number of Missing Values')\n",
    "plt.title('Top 20 Columns with Missing Values')\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RXLti9n6HyW"
   },
   "source": [
    "**Correlation Heatmap**\n",
    "- Purpose: Examine pairwise correlations among numeric features.\n",
    "\n",
    "- Why: Detect redundant features, multicollinearity, or strong predictive signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jgFZ8ZYs051F",
    "outputId": "6cd23245-b551-4c16-a9a7-0c45af04d29f"
   },
   "outputs": [],
   "source": [
    "# Correlation Matrix Heatmap for Numeric Features\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if 'PROSPECTID' in numeric_cols:\n",
    "    numeric_cols.remove('PROSPECTID')\n",
    "\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    mask=mask,\n",
    "    annot=False,\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    "    square=True,\n",
    "    fmt='.2f',\n",
    "    cbar_kws={\"shrink\": .8}\n",
    ")\n",
    "\n",
    "plt.title('Correlation Matrix of Numeric Features', fontsize=18, pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nci_uiBk7ngf"
   },
   "source": [
    "**Box Plots by Approval Status**\n",
    "- Purpose: Compare feature distributions across approval outcomes.\n",
    "\n",
    "- Why: Highlights whether features like credit score, age, or income differ systematically between approved and rejected groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 971
    },
    "id": "-SVvNd8C09wi",
    "outputId": "6114f57f-c4e4-4f71-8c5b-b5b34047fc90"
   },
   "outputs": [],
   "source": [
    "# Box Plots for Key Features by Approval Status\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "df.boxplot(column='Credit_Score', by='Approved_Flag', ax=axes[0, 0])\n",
    "axes[0,0].set_title('Credit Score by Approval Status')\n",
    "axes[0,0].set_xlabel('Approved_Flag')\n",
    "\n",
    "df.boxplot(column='AGE', by='Approved_Flag', ax=axes[0, 1])\n",
    "axes[0,1].set_title('Age by Approval Status')\n",
    "axes[0,1].set_xlabel('Approved_Flag')\n",
    "\n",
    "df.boxplot(column='Total_TL', by='Approved_Flag', ax=axes[1, 0])\n",
    "axes[1,0].set_title('Total Trade Lines by Approval Status')\n",
    "axes[1,0].set_xlabel('Approved_Flag')\n",
    "\n",
    "# Log of Net Monthly Income\n",
    "income_plot = df[df['NETMONTHLYINCOME'] > 0].copy()\n",
    "income_plot['Log_Income'] = np.log10(income_plot['NETMONTHLYINCOME'])\n",
    "income_plot.boxplot(column='Log_Income', by='Approved_Flag', ax=axes[1, 1])\n",
    "axes[1,1].set_title('Log(Net Monthly Income) by Approval Status')\n",
    "axes[1,1].set_xlabel('Approved_Flag')\n",
    "\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XR9paV61Lhv"
   },
   "source": [
    "# **Summary Statistics and Feature Analysis**\n",
    "Providing descriptive stats for key variables stratified by target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoLexWhz711r"
   },
   "source": [
    "**Grouped Statistics**\n",
    "- Purpose: Generate descriptive statistics (mean, median, std) of numeric features split by target.\n",
    "\n",
    "- Why: Quantifies differences in applicant profiles across approval outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "id": "j9cYvnGR1LIn",
    "outputId": "09afc633-36f3-4b9b-c053-c9f6cce3ac63"
   },
   "outputs": [],
   "source": [
    "# Key statistics by target\n",
    "print(\"=== Credit Score Statistics per Approval Flag ===\")\n",
    "print(df.groupby('Approved_Flag')['Credit_Score'].describe())\n",
    "\n",
    "print(\"\\n=== Age Statistics per Approval Flag ===\")\n",
    "print(df.groupby('Approved_Flag')['AGE'].describe())\n",
    "\n",
    "print(\"\\n=== Total Trade Lines per Approval Flag ===\")\n",
    "print(df.groupby('Approved_Flag')['Total_TL'].describe())\n",
    "\n",
    "'''\n",
    "# Active-to-total trade line ratio\n",
    "df['Active_to_Total_Ratio'] = df['Tot_Active_TL'] / (df['Total_TL'] + 1e-6)\n",
    "print(\"\\n=== Active to Total Trade Line Ratio per Approval Flag ===\")\n",
    "print(df.groupby('Approved_Flag')['Active_to_Total_Ratio'].describe())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JZCMPDv1QD6"
   },
   "source": [
    "# **Categorical Variables Analysis**\n",
    "Examine distribution across categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4Pk1P0T7_94"
   },
   "source": [
    "**Categorical Feature Analysis**\n",
    "- Purpose: Analyze distributions of categorical features (e.g., gender, occupation, region) relative to approval flag.\n",
    "\n",
    "- Why: Identifies categorical variables that may influence approval probability.\n",
    "\n",
    "How:\n",
    "\n",
    "- Crosstabs show counts and percentages.\n",
    "\n",
    "- Stacked bar charts visualize category breakdown across approval outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tkh0bR9Q1TqX",
    "outputId": "0d17477b-bdc1-4e26-e4df-0c2a944be3e8"
   },
   "outputs": [],
   "source": [
    "# Automatically detect categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Exclude target column if present\n",
    "if 'Approved_Flag' in categorical_cols:\n",
    "    categorical_cols.remove('Approved_Flag')\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n=== {col} Distribution by Approval Flag ===\")\n",
    "\n",
    "        # Crosstab: counts\n",
    "        counts = pd.crosstab(df[col], df['Approved_Flag'])\n",
    "\n",
    "        # Crosstab: percentages\n",
    "        percentages = pd.crosstab(df[col], df['Approved_Flag'], normalize='columns') * 100\n",
    "\n",
    "        # Merge counts + percentages into one table\n",
    "        summary = counts.astype(str) + \" (\" + percentages.round(1).astype(str) + \"%)\"\n",
    "        print(summary)\n",
    "\n",
    "        # Plot stacked bar chart\n",
    "        ax = (percentages.T).plot(\n",
    "            kind=\"bar\",\n",
    "            stacked=True,\n",
    "            figsize=(8, 4),\n",
    "            colormap=\"Set2\"\n",
    "        )\n",
    "        plt.title(f\"{col} Distribution by Approval Flag\")\n",
    "        plt.ylabel(\"Percentage\")\n",
    "        plt.xlabel(\"Approval Flag\")\n",
    "\n",
    "        # ðŸ”‘ Tilt x-axis labels\n",
    "        plt.xticks(rotation=30, ha=\"right\")\n",
    "\n",
    "        plt.legend(title=col, bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdS5Er__1ZWG"
   },
   "source": [
    "# **Missing Values Analysis by Target**\n",
    "Identify variables with missing data stratified by target class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1vm0pMr1Yo-"
   },
   "outputs": [],
   "source": [
    "missing_by_target = (\n",
    "    df.drop(columns=['Approved_Flag'])\n",
    "      .groupby(df['Approved_Flag'])\n",
    "      .apply(lambda x: x.isnull().sum())\n",
    "      .T\n",
    ")\n",
    "\n",
    "missing_by_target_pct = (\n",
    "    df.drop(columns=['Approved_Flag'])\n",
    "      .groupby(df['Approved_Flag'])\n",
    "      .apply(lambda x: x.isnull().mean() * 100)\n",
    "      .T\n",
    ")\n",
    "\n",
    "# sort the missingness across all target classes\n",
    "top_missing = (\n",
    "    missing_by_target_pct\n",
    "    .assign(Max_Missing=lambda x: x.max(axis=1))   # new col = max missing %\n",
    "    .sort_values(by='Max_Missing', ascending=False)\n",
    "    .drop(columns=['Max_Missing'])\n",
    "    .head(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 971
    },
    "id": "CB_DgQqAuC0_",
    "outputId": "81c36bc9-340c-4e3e-bced-d415992d1184"
   },
   "outputs": [],
   "source": [
    "print(\"=== Missing Value Percentages by Approval Flag (Top 10 across all classes) ===\")\n",
    "display(top_missing.round(2))\n",
    "\n",
    "# --- Visualization ---\n",
    "ax = top_missing.plot(kind=\"bar\", figsize=(12, 6), colormap=\"Set2\")\n",
    "\n",
    "plt.title(\"Top 10 Features with Missing Values by Approval Flag\", fontsize=16, pad=15)\n",
    "plt.ylabel(\"Missing %\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.0f}%'))\n",
    "plt.legend(title=\"Approved_Flag\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOEqDubI1pBw"
   },
   "source": [
    "# **Data Quality Summary**\n",
    "Summary statistics for dataset integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQaw3BgD1p_K",
    "outputId": "30500650-a002-4c25-b5d5-5b9cbc10a131"
   },
   "outputs": [],
   "source": [
    "total_records = len(df)\n",
    "total_features = len(df.columns)\n",
    "numeric_features = len(numeric_cols)\n",
    "categorical_features = len(categorical_cols)\n",
    "missing_percentage = df.isnull().sum().sum() / (total_records * total_features) * 100\n",
    "\n",
    "print(f\"Total records: {total_records}\")\n",
    "print(f\"Total features: {total_features}\")\n",
    "print(f\"Numeric features: {numeric_features}\")\n",
    "print(f\"Categorical features: {categorical_features}\")\n",
    "print(f\"Overall missing value percentage: {missing_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ertna3ge1vBd",
    "outputId": "3f270c7f-9115-49c9-8791-f4928f8ed15a"
   },
   "outputs": [],
   "source": [
    "# Features with >50% missing data\n",
    "\n",
    "high_missing = df.isnull().sum() / total_records * 100\n",
    "high_missing_features = high_missing[high_missing > 50]\n",
    "\n",
    "if not high_missing_features.empty:\n",
    "    print(f\"\\nFeatures with >50% missing values ({len(high_missing_features)} features):\")\n",
    "    print(high_missing_features.sort_values(ascending=False))\n",
    "else:\n",
    "    print(\"\\nNo features with >50% missing values found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UT1-AhDhOm-f"
   },
   "source": [
    "# Handling Missing Values\n",
    "Using Iterative Imputer for Bayesian Ridge Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xv0qV6MmOwqF"
   },
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tiKERefOzE8"
   },
   "outputs": [],
   "source": [
    "# make a new dataframe after handling missing values\n",
    "\n",
    "df_reg = df.copy()\n",
    "\n",
    "num_cols = df_reg.select_dtypes(include=[np.number]).columns\n",
    "cat_cols = df_reg.select_dtypes(exclude=[np.number]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avWnWYasO7y4"
   },
   "outputs": [],
   "source": [
    "# encode categorical data for imputation\n",
    "\n",
    "le_dict = {} # store imputations\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_reg[col] = df_reg[col].astype(str)\n",
    "    df_reg[col] = le.fit_transform(df_reg[col])\n",
    "    le_dict[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXWxHfCnPHaK"
   },
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(random_state=17, max_iter=10, sample_posterior=False) # check random value\n",
    "df_reg[num_cols] = imputer.fit_transform(df_reg[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCShMNn9PM02"
   },
   "outputs": [],
   "source": [
    "# decode transformed cols back to categorical\n",
    "\n",
    "for col in cat_cols:\n",
    "    df_reg[col] = le_dict[col].inverse_transform(df_reg[col].astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 764
    },
    "id": "6d3y8WYzPYZ1",
    "outputId": "419a00d4-712e-43ae-9849-1701ad2a2e4a"
   },
   "outputs": [],
   "source": [
    "# check imputation results\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "sns.heatmap(df_reg.isnull(), cbar=False, cmap=\"viridis\")\n",
    "plt.title(\"Missing Values Heatmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fSnZ5qHPdOY",
    "outputId": "573f3c81-6ad9-49b0-b529-6e23ecbbd29e"
   },
   "outputs": [],
   "source": [
    "df_reg.to_csv(\"merged_regression_imputed.csv\", index=False)\n",
    "print(\"Regression-imputed dataset saved as merged_regression_imputed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHPgWRt-PjFx"
   },
   "source": [
    "# Outlier Elimination\n",
    "Based on BoxCox Plots and Percentile Clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFGnOzyGY7y0"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import boxcox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEvqUxnFPiyq"
   },
   "outputs": [],
   "source": [
    "# setup outlier detection from numerical columns\n",
    "\n",
    "df_out = df_reg.copy()\n",
    "num_cols = df_out.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "outlier_report = {}\n",
    "transformation_report = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bziE_i8RY_ag"
   },
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "\n",
    "    Q1 = df_out[col].quantile(0.25)\n",
    "    Q3 = df_out[col].quantile(0.75)\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = ((df_out[col] < lower) | (df_out[col] > upper)).sum()\n",
    "    pct_outliers = 100 * outliers / df_out.shape[0]\n",
    "    outlier_report[col] = pct_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8SHmvRIbZE1g",
    "outputId": "2fdd16f4-a8a9-445a-839d-9f73fe621435"
   },
   "outputs": [],
   "source": [
    "# show outlier percentage\n",
    "\n",
    "outlier_df = pd.DataFrame.from_dict(outlier_report, orient='index', columns=['% Outliers'])\n",
    "print(\"Outlier percentage per numeric column:\\n\", outlier_df.sort_values('% Outliers', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AtNfgDoZJkU"
   },
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    skew = df_out[col].skew()\n",
    "    pct_outliers = outlier_df.loc[col, '% Outliers']\n",
    "\n",
    "    if pct_outliers > 5:  # Significant outliers\n",
    "        if skew > 1:\n",
    "            # Try Box-Cox (requires strictly positive values)\n",
    "            if (df_out[col] > 0).all():\n",
    "                df_out[col], _ = boxcox(df_out[col])  # Box-Cox transform\n",
    "                transformation_report[col] = f\"Box-Cox (skew={skew:.2f}, outliers={pct_outliers:.1f}%)\"\n",
    "            else:\n",
    "                df_out[col] = np.log1p(df_out[col] - df_out[col].min() + 1)\n",
    "                transformation_report[col] = f\"log1p (skew={skew:.2f}, outliers={pct_outliers:.1f}%)\"\n",
    "        else:\n",
    "            # Clip at 1st and 99th percentile\n",
    "            Q1 = df_out[col].quantile(0.01)\n",
    "            Q99 = df_out[col].quantile(0.99)\n",
    "            df_out[col] = df_out[col].clip(Q1, Q99)\n",
    "            transformation_report[col] = f\"Clipped at 1st-99th pct (skew={skew:.2f}, outliers={pct_outliers:.1f}%)\"\n",
    "    else:\n",
    "        transformation_report[col] = \"No action (low outliers)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2BXy5OXGZYPt",
    "outputId": "6f0643c6-23c3-4c45-ad7c-429e4dee8ad7"
   },
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame.from_dict(transformation_report, orient='index', columns=['Action Taken'])\n",
    "print(\"\\nSummary of transformations:\\n\", summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iSBSN51UZceu",
    "outputId": "5cd6227d-5b5a-469a-904f-1eecc467adda"
   },
   "outputs": [],
   "source": [
    "# Plot first 6 numerical columns\n",
    "\n",
    "for col in num_cols[:6]:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "    # Boxplots\n",
    "    sns.boxplot(x=df_reg[col], ax=axes[0], color=\"skyblue\")\n",
    "    axes[0].set_title(f\"Before: {col}\")\n",
    "\n",
    "    sns.boxplot(x=df_out[col], ax=axes[1], color=\"lightgreen\")\n",
    "    axes[1].set_title(f\"After: {col}\")\n",
    "\n",
    "    # Distribution comparison\n",
    "    sns.kdeplot(df_reg[col], ax=axes[2], label=\"Before\", fill=True, alpha=0.4, color=\"blue\")\n",
    "    sns.kdeplot(df_out[col], ax=axes[2], label=\"After\", fill=True, alpha=0.4, color=\"green\")\n",
    "    axes[2].set_title(f\"Distribution: {col}\")\n",
    "    axes[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-EQfbWfZjlz"
   },
   "source": [
    "# **Feature Selection**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0nvEs50jZdZ_"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_selection import chi2, SelectKBest, f_regression, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PiqOogedaBVS"
   },
   "outputs": [],
   "source": [
    "df_fs = df_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6K6-L_VHZzFS",
    "outputId": "6241e32c-03d9-4c4f-e397-b80a7e852846"
   },
   "outputs": [],
   "source": [
    "# select the target column\n",
    "\n",
    "possible_targets = [\"TARGET\", \"target\", \"label\", \"PerformanceTag\", \"Target\"]\n",
    "target = None\n",
    "\n",
    "for col in df_fs.columns:\n",
    "    if col in possible_targets:\n",
    "        target = col\n",
    "        break\n",
    "\n",
    "if target is None:\n",
    "    target = df_fs.columns[-1]\n",
    "\n",
    "print(f\"Target column detected: {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWtccoibZ4em"
   },
   "outputs": [],
   "source": [
    "y = df_fs[target]\n",
    "X = df_fs.drop(columns=[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CjWRpABcaKgD"
   },
   "outputs": [],
   "source": [
    "if y.dtype == \"object\":\n",
    "    y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66daROqQaMBe"
   },
   "outputs": [],
   "source": [
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNQAht9faPY6"
   },
   "outputs": [],
   "source": [
    "# categorical features encoding\n",
    "\n",
    "if len(cat_cols) > 0:\n",
    "    encoder = OneHotEncoder(drop=\"first\", sparse_output=False, handle_unknown=\"ignore\")\n",
    "    X_cat = encoder.fit_transform(X[cat_cols])\n",
    "    selected_cat_features = encoder.get_feature_names_out(cat_cols)\n",
    "    X_cat_selected = X_cat\n",
    "else:\n",
    "    selected_cat_features = []\n",
    "    X_cat_selected = np.empty((len(X),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLaMezQm1Jct"
   },
   "outputs": [],
   "source": [
    "task = \"classification\"   # or \"regression\"\n",
    "k = 20                    # number of top features to keep\n",
    "force_keep = [\"Credit_Score\"]   # features you ALWAYS want to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qav78LqEaV9m",
    "outputId": "3403cc57-537c-42a2-e0c0-10d7ed4e9d8e"
   },
   "outputs": [],
   "source": [
    "if len(num_cols) > 0:\n",
    "\n",
    "    X_num = X[num_cols]\n",
    "    scaler = StandardScaler()\n",
    "    X_num_scaled = scaler.fit_transform(X_num)\n",
    "\n",
    "    # Decide regression vs classification automatically\n",
    "    if len(np.unique(y)) > 10:\n",
    "        scores, p_values = f_regression(X_num_scaled, y)\n",
    "    else:\n",
    "        scores, p_values = f_classif(X_num_scaled, y)\n",
    "\n",
    "    # Build DataFrame\n",
    "    anova_df = pd.DataFrame({\n",
    "        \"Feature\": num_cols,\n",
    "        \"F_Score\": scores,\n",
    "        \"p_value\": p_values\n",
    "    })\n",
    "\n",
    "    # Sort descending by F-score\n",
    "    anova_df = anova_df.sort_values(\"F_Score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Select top k features\n",
    "    k = min(20, X_num.shape[1])\n",
    "    top_features = anova_df.head(k)\n",
    "\n",
    "    # Output\n",
    "    print(\"\\nANOVA/F-test scores (descending order):\")\n",
    "    print(anova_df)\n",
    "    print(f\"\\nTop {k} numerical features (ANOVA/F-test):\")\n",
    "    print(top_features)\n",
    "\n",
    "    # Keep top features\n",
    "    selected_num_features = top_features[\"Feature\"].values\n",
    "    X_num_selected = X_num_scaled[:, [list(num_cols).index(f) for f in selected_num_features]]\n",
    "\n",
    "else:\n",
    "    selected_num_features = []\n",
    "    X_num_selected = np.empty((len(X), 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k4-ITAmsaj69",
    "outputId": "ed4224e3-c257-4208-c05a-6812adedfde7"
   },
   "outputs": [],
   "source": [
    "X_selected = np.hstack([X_cat_selected, X_num_selected])\n",
    "selected_features = list(selected_cat_features) + list(selected_num_features)\n",
    "\n",
    "df_selected = pd.DataFrame(X_selected, columns=selected_features, index=X.index)\n",
    "df_selected[target] = y\n",
    "\n",
    "print(\"\\n Final selected dataset shape:\", df_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hggzqW9Sansm",
    "outputId": "1d54ac6c-3eaf-46e6-965f-aae1e6cbde0f"
   },
   "outputs": [],
   "source": [
    "output_path = \"selected_features.csv\"\n",
    "df_selected.to_csv(output_path, index=False)\n",
    "print(f\"Selected dataset saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tZlZcDfa0cB"
   },
   "source": [
    "# Selecting Common Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ETYnjILa-1N",
    "outputId": "6e55548e-05da-427a-e36a-11f62e9264cd"
   },
   "outputs": [],
   "source": [
    "# training features (from your merged/cleaned dataset)\n",
    "train_features = set(X.columns)\n",
    "\n",
    "# unseen features (from your provided list)\n",
    "unseen_features = set(unseen_df.columns)\n",
    "\n",
    "# intersection\n",
    "common_features = list(train_features.intersection(unseen_features))\n",
    "print(\"Common features available for both training & unseen scoring:\\n\", common_features)\n",
    "\n",
    "# keep only these for training\n",
    "X_final = X[common_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lRtRxKHbCXh"
   },
   "source": [
    "# **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMw8N7Fk0rWz",
    "outputId": "3f0e9c63-3436-4e2f-a25f-fd1ff50d61d4"
   },
   "outputs": [],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D7AxNgcIbFi9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tKBtkae4bI8_"
   },
   "outputs": [],
   "source": [
    "# segregating columns for corresponding transformation\n",
    "\n",
    "cat_cols = X_final.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "num_cols = X_final.select_dtypes(exclude=[\"object\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYPezzWUbX_o"
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", drop=\"first\"), cat_cols),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBnwY7rWbbnV"
   },
   "outputs": [],
   "source": [
    "# split 80:20\n",
    "\n",
    "y_final = y\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_final, y_final, test_size=0.2, random_state=17, stratify=y_final\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4bzg5SGbwco"
   },
   "outputs": [],
   "source": [
    "# list of models to be used and compared among\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=17),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=200, random_state=17),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=17),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"XGBoost\": xgb.XGBClassifier( n_estimators=200, learning_rate=0.1, max_depth=7, random_state=17, eval_metric=\"logloss\" ),\n",
    "    \"CatBoost\": CatBoostClassifier( iterations=200, learning_rate=0.1, depth=7, random_state=17, verbose=0 )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWmHFQaCb1F5",
    "outputId": "68eb8f28-0707-4274-8ca6-4ff7e74fcdb8"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    pipe = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)   # preprocess + fit model\n",
    "    y_pred = pipe.predict(X_val) # preprocess + predict\n",
    "\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(y_val, y_pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_val, y_pred, average=\"weighted\")\n",
    "\n",
    "    results.append([name, acc, prec, rec, f1])  # store results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "htUONRHEcIg3",
    "outputId": "114099b7-c667-473c-c795-615453a166b5"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(\n",
    "    results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
    ")\n",
    "\n",
    "print(\"\\nModel Comparison Results:\\n\")\n",
    "print(results_df.sort_values(\"F1-score\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "DEejvM5_cWmV",
    "outputId": "0c5d0836-ca1b-42df-af98-b797ff419c81"
   },
   "outputs": [],
   "source": [
    "# visualization\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\"]\n",
    "\n",
    "# Melt results for grouped bar chart\n",
    "results_melted = results_df.melt(\n",
    "    id_vars=\"Model\",\n",
    "    value_vars=metrics,\n",
    "    var_name=\"Metric\",\n",
    "    value_name=\"Score\"\n",
    ")\n",
    "\n",
    "# Sort models by F1-score before plotting\n",
    "order = results_df.sort_values(\"F1-score\", ascending=False)[\"Model\"]\n",
    "\n",
    "sns.barplot(\n",
    "    data=results_melted,\n",
    "    x=\"Model\",\n",
    "    y=\"Score\",\n",
    "    hue=\"Metric\",\n",
    "    order=order\n",
    ")\n",
    "\n",
    "plt.title(\"Model Performance Comparison\", fontsize=14, weight=\"bold\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"\")\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\", title=\"Metric\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
